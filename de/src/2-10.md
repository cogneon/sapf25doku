## Simon Dückert - State of GenAI - was in meiner Wissensarbeit wirklich, wirklich funktioniert

Simon präsentierte in seinem Vortrag eine praxisnahe Bestandsaufnahme der aktuellen Nutzung von Generativer KI in Unternehmen. Der Fokus lag dabei bewusst auf *"was wirklich, wirklich funktioniert"* jenseits der Marketingversprechen der Anbieter. Als Wissensmanagement-Experte mit langjähriger Erfahrung bei größeren Unternehmen wie Siemens und Audi beleuchtete er konkrete Anwendungsfälle, technische Entwicklungen und praktische Herausforderungen beim Einsatz von KI-Tools im Arbeitsalltag.

## Aufbau und Gliederung des Vortrags

Der Vortrag gliederte sich in folgende Hauptbereiche:

1. **Einordnung und Kontext**: Historische Entwicklung von Technologiewellen im Wissensmanagement
2. **Aktuelle Nutzungstrends**: Auswertung der HBR-Studie zu realen Use Cases
3. **Technische Entwicklungen**: Überblick über Modelle, Parameter und neue Funktionen
4. **Agentic AI und neue Paradigmen**: Von Chatbots zu intelligenten Agenten
5. **Praktische Anwendungsbeispiele**: Konkrete Workflows und Tools
6. **Vibe-Coding**: Programmierung durch natürliche Sprache

## Kernaussagen

**Zur kognitiven Kränkung der Menschheit:**
*"Im Moment scheint immer mehr durch, dass uns so eine kognitive Kränkung erwischt. Also dass wir sagen, Sachen, wo wir bisher gesagt haben, das muss aber auf jeden Fall Mensch machen, diesen Text muss ein Mensch schreiben, auf einmal können das Maschinen."*

**Zur Diskrepanz zwischen Erwartung und Realität:**
*"Was so auf Folien gezeigt wird und was die Hersteller uns erzählen, was man damit alles tun könnte. Und wenn man dann mal die Leute fragt, was sie denn wirklich damit tun, da gibt es doch einen ziemlich großen Gap dazwischen."*

**Zu den vier Prinzipien im Umgang mit KI:**
*"Sprich mit der KI, als wäre es ein Mensch. Und dann steht in Klammern, aber denk dran, es ist keiner."*

**Zur Modellauswahl:**
*"Wenn Leute die Wahl haben, mache ich irgendwas im Microsoft Copilot oder nutze ich ChatGPT, hat ChatGPT immer das bessere Ergebnis und schnellere Ergebnis."*

**Zu Vibe-Coding:**
*"Die einzige Programmiersprache, die man in Zukunft noch kennen muss, ist Deutsch. Also ich sage der KI einfach, was ich haben will und die KI entwickelt die Software dazu."*

## Offene Fragestellungen

Während des Vortrags wurden verschiedene ungeklärte Aspekte angesprochen:

- Wie können Unternehmen den optimalen Weg zwischen verschiedenen KI-Modellen und -Anbietern finden?
- Welche Auswirkungen haben die hohen Betriebskosten (geschätzt 1 Milliarde Dollar monatlich bei OpenAI) auf die zukünftige Verfügbarkeit und Preisgestaltung?
- Wie kann die Qualität von dokumentenbasierten KI-Anwendungen systematisch verbessert werden?
- Welche Rolle wird das Model Context Protocol (MCP) als "USB für AI" in der Praxis spielen?
- Wie entwickelt sich die Balance zwischen lokalen und Cloud-basierten KI-Lösungen unter Datenschutzaspekten?

## Handlungsempfehlungen

### Für AI Literacy in Organisationen:
- Durchführung von Promptathons, Barcamps und Communities für peer-to-peer Lernen
- Aufbau von internen Meetups und Erfahrungsaustausch nach der Basisqualifikation
- Fokus auf schnelles voneinander Lernen und gegenseitiges Abschauen von Anwendungsfällen

### Für die Dokumentenverarbeitung:
- Vorzuverarbeitung von PDFs und Office-Dokumenten mit Tools wie Dockling, Lama Parse oder Tesseract
- Konvertierung in maschinenlesbare Formate wie Markdown für bessere KI-Performance
- Kuratierte Sammlungen anlegen statt ungefilterte Datenbanken anzubinden

### Für die Modellauswahl:
- Bewusste Entscheidung zwischen verschiedenen Sprachmodellen je nach Anwendungsfall
- Bei komplexen Aufgaben Reasoning-Modelle wie O3 oder O1 verwenden
- Für literarische Texte Claude gegenüber ChatGPT bevorzugen
- Web-Search aktivieren für aktuelle Informationen jenseits des Knowledge Cut-Off

### Für praktische Anwendungen:
- Deep Research für Markt- und Wettbewerbsanalysen einsetzen
- Vibe-Coding für einfache Automatisierungsaufgaben ausprobieren
- Agentic AI-Ansätze für komplexere Workflows evaluieren
- Model Context Protocol (MCP) für standardisierte Tool-Integration vorbereiten

### Technische Empfehlungen:
- Parameter wie Web-Search, Deep Research und Canvas-Funktionen bewusst einsetzen
- Lokale Modelle für datenschutzkritische Anwendungen evaluieren
- Multimodale Fähigkeiten (Text, Bild, Sprache) systematisch nutzen
- Memory-Funktionen für projektbezogene Kontinuität implementieren
